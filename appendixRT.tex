\section*{Apêndice: Código R para os Resultados Apresentados}

\subsection*{Introdução}

\begin{verbatim}
# Tamanho amostral "n"; parâmetros "mu", "s2" (sigma^2) e "nu" do modelo para
# a distribuição amostral e hiperparâmetros m, V, a e d das distribuições "a
# priori" (somente para "mu" e "s2"):

n = 500; mu = 11; s2 = 0.64; nu = 0.2; m = 11; V = 1; a = 7; d = 4

# Geração hierárquica da amostra de tamanho "n" do modelo:

U_pdf = function(n, nu) {
	u = sample(c(100, 1), prob=c(nu, 1-nu), size=n, replace=T)
}

set.seed(122019)

u = U_pdf(n, nu)
sam = rnorm(n, mu, sqrt(s2*u))

# Histograma e estatísticas da amostra gerada do modelo (figura 1):

par(mar = c(5,5,3,2))
hist(sam, breaks=100, prob=T, main="", xlim = c(-10, 40), ylim = c(0, 0.5),
	 xlab = "Amostra do modelo", ylab = "Densidade empírica")
library(moments); mean(sam); var(sam); skewness(sam); kurtosis(sam)

# Cálculo do logaritmo do núcleo da distribuição "a posteriori" original:

logA = function(X, mu, sigma2, nu) {
	n = length(X)
	k1 = (nu/10)*exp(-(X-mu)^2/(2*100*sigma2))
	k2 = (1-nu)*exp(-(X-mu)^2/(2*sigma2))
	k = log(k1 + k2)
	return(k)
}

logh = function(n, mu, sigma2, nu, m, V, a, d) {
	k1 = -((n + 1)/2 + a + 1)*log(sigma2)
	k2 = -((mu - m)^2/(2*V) + d)/sigma2
	k = k1 + k2
	return(k)
}

logkpost = function(X, mu, sigma2, nu, m, V, a, d) {
	n = length(X)
	lA = logA(X, mu, sigma2, nu)
	lh = logh(n, mu, sigma2, nu, m, V, a, d)
	lkp = sum(lA) + lh
	return(lkp)}

# Gráficos dos intervalos de massa probabilística para cada parâmetro do
# núcleo da distribuição "a posteriori", fixados os demais, após algumas
# tentativas anteriores para redução dos limites do gráfico e melhor vi-
# sualização da curva (figuras 2a a 2c):

mu_sup=seq(10.8, 11.2, 0.001); t_mu=length(mu_sup); kp_mu=numeric(t_mu)

for(i in 1:t_mu) {
	kp_mu[i] = exp(logkpost(X=sam,
	mu=mu_sup[i], sigma2=s2, nu=nu, m=m, V=V, a=a, d=d))
	}
plot(mu_sup, kp_mu, type="l", main="",
     xlab=expression(paste(mu)), ylab="")

s2_sup=seq(0.4, 0.8, 0.001); t_s2=length(s2_sup); kp_s2=numeric(t_s2)

for(i in 1:t_s2) {
	kp_s2[i] = exp(logkpost(X=sam,
	mu=mu, sigma2=s2_sup[i], nu=nu, m=m, V=V, a=a, d=d))
	}
plot(s2_sup, kp_s2, type="l", main="",
	 xlab=expression(paste(sigma^2)), ylab="")

nu_sup=seq(0.1, 0.3, 0.001); t_nu=length(nu_sup); kp_nu=numeric(t_nu)

for(i in 1:t_nu) {
	kp_nu[i] = exp(logkpost(X=sam,
	mu=mu, sigma2=s2, nu=nu_sup[i], m=m, V=V, a=a, d=d))
	}
plot(nu_sup, kp_nu, type="l", main="",
     xlab=expression(paste(nu)), ylab="")
\end{verbatim}

\subsection*{O Método da Quadratura de Riemann}

\begin{verbatim}

# Cenários considerados, variando no número de subintervalos utilizados:

L1 = 15; L2 = 50; L3 = 100

# Tamanhos dos subintervalos, dada a combinação de cenário e parâmetro, e
# grades definidas pelos mesmos:

mu_step1 = (11.13 - 10.85)/L1; mu_gr1 = seq(10.85, 11.13, mu_step1)
mu_step2 = (11.13 - 10.85)/L2; mu_gr2 = seq(10.85, 11.13, mu_step2)
mu_step3 = (11.13 - 10.85)/L3; mu_gr3 = seq(10.85, 11.13, mu_step3)

s2_step1 = (0.78 - 0.48)/L1; s2_gr1 = seq(0.48, 0.78, s2_step1)
s2_step2 = (0.78 - 0.48)/L2; s2_gr2 = seq(0.48, 0.78, s2_step2)
s2_step3 = (0.78 - 0.48)/L3; s2_gr3 = seq(0.48, 0.78, s2_step3)

nu_step1 = (0.26 - 0.13)/L1; nu_gr1 = seq(0.13, 0.26, nu_step1)
nu_step2 = (0.26 - 0.13)/L2; nu_gr2 = seq(0.13, 0.26, nu_step2)
nu_step3 = (0.26 - 0.13)/L3; nu_gr3 = seq(0.13, 0.26, nu_step3)

# Combinando as três grades unidimensionais em cada cenário, todas com
# número igual de subintervalos e de pontos (nos limites dos interval-
# os) para integração numérica:

grid_tri1 = cbind(mu_gr1, s2_gr1, nu_gr1); l1 = nrow(grid_tri1)
grid_tri2 = cbind(mu_gr2, s2_gr2, nu_gr2); l2 = nrow(grid_tri2)
grid_tri3 = cbind(mu_gr3, s2_gr3, nu_gr3); l3 = nrow(grid_tri3)

# Produto triplo dos tamanhos dos subintervalos em cada cenário:

prod_step1 = mu_step1*s2_step1*nu_step1
prod_step2 = mu_step2*s2_step2*nu_step2
prod_step3 = mu_step3*s2_step3*nu_step3

# Cálculo do inverso da constante de proporcionalidade em cada cenário:

cprop = function(l, X, mgr, s2gr, ngr, prst, m, V, a, d) {
	c = 0
	for (i in 1:l) {
		for (j in 1:l) {
			for (k in 1:l) {
				aux = logkpost(X, mgr[i], s2gr[j], ngr[k], m, V, a, d)
				c = c + exp(aux)*prst
			}
		}
	}
	return(c)
}

c1 = cprop(l=l1, X=sam, mgr=mu_gr1, s2gr=s2_gr1, ngr=nu_gr1,
		   prst=prod_step1, m=m, V=V, a=a, d=d)
c2 = cprop(l=l2, X=sam, mgr=mu_gr2, s2gr=s2_gr2, ngr=nu_gr2,
		   prst=prod_step2, m=m, V=V, a=a, d=d)
c3 = cprop(l=l3, X=sam, mgr=mu_gr3, s2gr=s2_gr3, ngr=nu_gr3,
		   prst=prod_step3, m=m, V=V, a=a, d=d)
c1; c2; c3

# Cálculo das densidades "a posteriori" marginais em cada cenário, com
# uso do produto duplo dos tamanhos dos subintervalos em cada cenário:

pr1_dup12 = mu_step1*s2_step1
pr1_dup13 = mu_step1*nu_step1
pr1_dup23 = s2_step1*nu_step1
\end{verbatim}

\newpage

\begin{verbatim}
pr2_dup12 = mu_step2*s2_step2
pr2_dup13 = mu_step2*nu_step2
pr2_dup23 = s2_step2*nu_step2

pr3_dup12 = mu_step3*s2_step3
pr3_dup13 = mu_step3*nu_step3
pr3_dup23 = s2_step3*nu_step3

postmu_quarie = function(l, X, mgr, s2gr, ngr, prst, m, V, a, d, c) {
	postmu = numeric(l)
	for (i in 1:l) {
		postconj = 0
		for (j in 1:l) {
			for(k in 1:l) {
				aux = logkpost(X, mgr[i], s2gr[j], ngr[k], m, V, a, d)
				postconj = postconj + exp(aux)*prst
			}
		}
		postmu[i] = postconj/c
	}
	return(postmu)
}

pmq1 = postmu_quarie(l=l1, X=sam, mgr=mu_gr1, s2gr=s2_gr1, ngr=nu_gr1,
					 prst=pr1_dup23, m=m, V=V, a=a, d=d, c=c1)
pmq2 = postmu_quarie(l=l2, X=sam, mgr=mu_gr2, s2gr=s2_gr2, ngr=nu_gr2,
					 prst=pr2_dup23, m=m, V=V, a=a, d=d, c=c2)
pmq3 = postmu_quarie(l=l3, X=sam, mgr=mu_gr3, s2gr=s2_gr3, ngr=nu_gr3,
					 prst=pr3_dup23, m=m, V=V, a=a, d=d, c=c3)

plot(mu_gr1,pmq1,type="l",main="",xlab=expression(paste(mu)),ylab="")
plot(mu_gr2,pmq2,type="l",main="",xlab=expression(paste(mu)),ylab="")
plot(mu_gr3,pmq3,type="l",main="",xlab=expression(paste(mu)),ylab="")

posts2_quarie = function(l, X, mgr, s2gr, ngr, prst, m, V, a, d, c) {
	posts2 = numeric(l)
	for (i in 1:l) {
		postconj = 0
		for (j in 1:l) {
			for(k in 1:l) {
				aux = logkpost(X, mgr[j], s2gr[i], ngr[k], m, V, a, d)
				postconj = postconj + exp(aux)*prst
			}
		}
		posts2[i] = postconj/c
	}
	return(posts2)
}

\end{verbatim}

\newpage

\begin{verbatim}
psq1 = posts2_quarie(l=l1, X=sam, mgr=mu_gr1, s2gr=s2_gr1, ngr=nu_gr1,
					 prst=pr1_dup13, m=m, V=V, a=a, d=d, c=c1)
psq2 = posts2_quarie(l=l2, X=sam, mgr=mu_gr2, s2gr=s2_gr2, ngr=nu_gr2,
					 prst=pr2_dup13, m=m, V=V, a=a, d=d, c=c2)
psq3 = posts2_quarie(l=l3, X=sam, mgr=mu_gr3, s2gr=s2_gr3, ngr=nu_gr3,
					 prst=pr3_dup13, m=m, V=V, a=a, d=d, c=c3)

plot(s2_gr1, psq1, type="l", main="", xlab=expression(paste(sigma^2)),
	 ylab="")
plot(s2_gr2, psq2, type="l", main="", xlab=expression(paste(sigma^2)),
	 ylab="")
plot(s2_gr3, psq3, type="l", main="", xlab=expression(paste(sigma^2)), 
	 ylab="")

postnu_quarie = function(l, X, mgr, s2gr, ngr, prst, m, V, a, d, c) {
	postnu = numeric(l)
	for (i in 1:l) {
		postconj = 0
		for (j in 1:l) {
			for(k in 1:l) {
				aux = logkpost(X, mgr[j], s2gr[k], ngr[i], m, V, a, d)
				postconj = postconj + exp(aux)*prst
			}
		}
		postnu[i] = postconj/c
	}
	return(postnu)
}

pnq1 = postnu_quarie(l=l1, X=sam, mgr=mu_gr1, s2gr=s2_gr1, ngr=nu_gr1,
					 prst=pr1_dup12, m=m, V=V, a=a, d=d, c=c1)
pnq2 = postnu_quarie(l=l2, X=sam, mgr=mu_gr2, s2gr=s2_gr2, ngr=nu_gr2,
					 prst=pr2_dup12, m=m, V=V, a=a, d=d, c=c2)
pnq3 = postnu_quarie(l=l3, X=sam, mgr=mu_gr3, s2gr=s2_gr3, ngr=nu_gr3,
					 prst=pr3_dup12, m=m, V=V, a=a, d=d, c=c3)

plot(nu_gr1,pnq1,type="l",main="",xlab=expression(paste(nu)),ylab="")
plot(nu_gr2,pnq2,type="l",main="",xlab=expression(paste(nu)),ylab="")
plot(nu_gr3,pnq3,type="l",main="",xlab=expression(paste(nu)),ylab="")
\end{verbatim}

\newpage

\begin{verbatim}
# Cálculo da média, variância, assimetria e curtose "a posteriori" para
# cada parâmetro:

stat_post = function(gr, marg, prst) {
	media = 0
	var = 0
	assim = 0
	cur = 0
	l = length(gr)
	
	aux1 = sum(gr*marg*prst)     # Aproxima 1º momento.
	aux2 = sum((gr^2)*marg*prst) # Aproxima 2º momento.
	aux3 = sum((gr^3)*marg*prst) # Aproxima 3º momento.
	aux4 = sum((gr^4)*marg*prst) # Aproxima 4º momento.
	
	media = aux1
	var = aux2 - (media)^2
	assim = (aux3 - 3*media*var - media^3)/(var^(3/2))
	cur = (aux4 - 4*media*aux3 + 6*media^2*aux2 - 3*(media^4))/(var^2)
	return(list(media, var, assim, cur))
}

stat_post(mu_gr1, pmq1, mu_step1)
stat_post(mu_gr2, pmq2, mu_step2)
stat_post(mu_gr3, pmq3, mu_step3)

stat_post(s2_gr1, psq1, s2_step1)
stat_post(s2_gr2, psq2, s2_step2)
stat_post(s2_gr3, psq3, s2_step3)

stat_post(nu_gr1, pnq1, nu_step1)
stat_post(nu_gr2, pnq2, nu_step2)
stat_post(nu_gr3, pnq3, nu_step3)

\end{verbatim}

\subsection*{O Método da Reamostragem Por Importância Sequencial (SIR)}

\begin{verbatim}
# Cálculo do logaritmo do núcleo da distribuição "a posteriori" reparametrizada:

logr = function(sigma2, nu) {
k = log(sigma2) + 3*log(nu) - log(1-nu)
return(k)
}
\end{verbatim}

\newpage

\begin{verbatim}
logkpost_re = function(X, mu, sigma2, nu, m, V, a, d) {
n = length(X)
lA = logA(X, mu, sigma2, nu)
lh = logh(n, mu, sigma2, nu, m, V, a, d)
lr = logr(sigma2, nu)
lkrp = sum(lA) + lh + lr
return(lkrp)
}

logkpost_re(sam, mu, s2, nu, m, V, a, d)

# Cenários de tamanhos do vetor de pesos e de amostras "a posteriori" via SIR:

aw1 = 5000; aw2 = 50000; aw3 = 500000
am1 = aw1/10; am2 = aw2/10; am3 = aw3/10

# Valores reparametrizados da diagonal principal da matriz de covariâncias
# da distribuição normal trivariada:

((11.13-10.85)/6)^2
((log(0.78)-log(0.48))/6)^2
((log(0.26/0.74)-log(0.13/0.87))/6)^2

# Geração de amostras da distribuição normal trivariada:

library(mvtnorm)

set.seed(122019)
r1_q = rmvnorm(aw1, mean=c(11, log(0.64), log(0.2/0.8)),
			   sigma=diag(c(0.0022, 0.0065, 0.0203)))
set.seed(122019)
r2_q = rmvnorm(aw2, mean=c(11, log(0.64), log(0.2/0.8)),
			   sigma=diag(c(0.0022, 0.0065, 0.0203)))
set.seed(122019)
r3_q = rmvnorm(aw3, mean=c(11, log(0.64), log(0.2/0.8)),
			   sigma=diag(c(0.0022, 0.0065, 0.0203)))

# Cálculo da densidade para cada ponto das amostras geradas:

d1_q = dmvnorm(r1_q, mean=c(11, log(0.64), log(0.2/0.8)), sigma=diag(3))
d2_q = dmvnorm(r2_q, mean=c(11, log(0.64), log(0.2/0.8)), sigma=diag(3))
d3_q = dmvnorm(r3_q, mean=c(11, log(0.64), log(0.2/0.8)), sigma=diag(3))
\end{verbatim}

\newpage

\begin{verbatim}
# Cálculo dos pesos de reamostragem:

weiSIR = function(X, r_q, m, V, a, d, d_q) {
	k = nrow(r_q)
	aux1 = aux2 = w = numeric(k)
	for(i in 1:k) {
		aux1[i] = logkpost_re(X=X, mu=r_q[i,1], sigma2=exp(r_q[i,2]),
							  nu=1/(1+exp(-r_q[i,3])), m=m, V=V, a=a,
							  d=d)
	}
	aux2 = aux1/d_q
	w = aux2/sum(aux2)
	return(w)
}

w1 = weiSIR(sam, r1_q, m, V, a, d, d1_q); sum(w1)
w2 = weiSIR(sam, r2_q, m, V, a, d, d2_q); sum(w2)
w3 = weiSIR(sam, r3_q, m, V, a, d, d3_q); sum(w3)

# Geração das amostras da densidade aproximada pelo método SIR com os pesos
# calculados acima:

set.seed(122019)
am1_mu_p = sample(x=r1_q[,1], size=am1, replace=T, prob=w1)
set.seed(122019)
am1_s2_p = sample(x=exp(r1_q[,2]), size=am1, replace=T, prob=w1)
set.seed(122019)
am1_nu_p = sample(x=1/(1+exp(-r1_q[,3])), size=am1, replace=T, prob=w1)

set.seed(122019)
am2_mu_p = sample(x=r2_q[,1], size=am2, replace=T, prob=w2)
set.seed(122019)
am2_s2_p = sample(x=exp(r2_q[,2]), size=am2, replace=T, prob=w2)
set.seed(122019)
am2_nu_p = sample(x=1/(1+exp(-r2_q[,3])), size=am2, replace=T, prob=w2)

set.seed(122019)
am3_mu_p = sample(x=r3_q[,1], size=am3, replace=T, prob=w3)
set.seed(122019)
am3_s2_p = sample(x=exp(r3_q[,2]), size=am3, replace=T, prob=w3)
set.seed(122019)
am3_nu_p = sample(x=1/(1+exp(-r3_q[,3])), size=am3, replace=T, prob=w3)
\end{verbatim}

\newpage

\begin{verbatim}
# Média; variância; assimetria; curtose e histogramas das amostras geradas:

library(moments)

st_sam_post = function(Xpar) {
	medi = mean(Xpar)
	vari = var(Xpar)
	assi = skewness(Xpar)
	curt = kurtosis(Xpar)
	return(list(media=medi, variancia=vari, assimetria=assi, curtose=curt))
}

st_sam_post(am1_mu_p)
hist(am1_mu_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(mu)), ylab="")
st_sam_post(am2_mu_p)
hist(am2_mu_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(mu)), ylab="")
st_sam_post(am3_mu_p)
hist(am3_mu_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(mu)), ylab="")

st_sam_post(am1_s2_p)
hist(am1_s2_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(sigma^2)), ylab="")
st_sam_post(am2_s2_p)
hist(am2_s2_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(sigma^2)), ylab="")
st_sam_post(am3_s2_p)
hist(am3_s2_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(sigma^2)), ylab="")

st_sam_post(am1_nu_p)
hist(am1_nu_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(nu)), ylab="")
st_sam_post(am2_nu_p)
hist(am2_nu_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(nu)), ylab="")
st_sam_post(am3_nu_p)
hist(am3_nu_p, breaks=50, prob=T, main="",
	 xlab=expression(paste(nu)), ylab="")
\end{verbatim}

\newpage

\subsection*{O Método de Monte Carlo via Cadeias de Markov (MCMC)}

\begin{verbatim}
# Cenários de tamanhos para amostragem da "posteriori" via MCMC com passos MH:

am1 = 500; am2 = 5000; am3 = 50000

# Geração de 3 amostras de uma uniforme padrão para o critério de aceitação no
# algoritmo de Metropolis-Hastings:

set.seed(122019); up1 = runif(am1)
set.seed(122019); up2 = runif(am2)
set.seed(122019); up3 = runif(am3)

# Ponto inicial da cadeia:

x = c(10.86, log(0.50), log(0.14/0.86))

# Vetores para receber amostras "a posteriori" da distribuição desejada:

am1_mu_p = am1_s2_p = am1_nu_p = numeric(am1)
am2_mu_p = am2_s2_p = am2_nu_p = numeric(am2)
am3_mu_p = am3_s2_p = am3_nu_p = numeric(am3)

# Geração das amostras "a posteriori" via com passos MH:

XparMH = function(X, m, V, a, d, x, var_d, up, seed) {
	k = length(up)
	am_mu_p = am_s2_p = am_nu_p = numeric(k)
	cont=0
	set.seed(122019)
	for(i in 1:k) {
		y = rmvnorm(1,mean=c(x[1],x[2],x[3]),sigma=diag(var_d))
		auy = exp(logkpost_re(sam,y[1],exp(y[2]),1/(1+exp(-y[3])),m,V,a,d))
		aux = exp(logkpost_re(sam,x[1],exp(x[2]),1/(1+exp(-x[3])),m,V,a,d))
		acep = min(c(1, auy/aux))
		if(up[i] <= acep) {
			am_mu_p[i] = y[1]
			am_s2_p[i] = exp(y[2])
			am_nu_p[i] = 1/(1+exp(-y[3]))
			x = y; cont = cont + 1
		}
		else {
			am_mu_p[i] = x[1]
			am_s2_p[i] = exp(x[2])
			am_nu_p[i] = 1/(1+exp(-x[3]))
		}
	}
	return(list(XparMH_mu=am_mu_p[(0.2*k + 1):k],
				XparMH_s2=am_s2_p[(0.2*k + 1):k],
				XparMH_nu=am_nu_p[(0.2*k + 1):k], taxa_acep=cont/k))
}
\end{verbatim}

\begin{verbatim}
am1_p = XparMH(X=sam, m=m, V=V, a=a, d=d,
			   x=x, var_d=c(0.0022, 0.0065, 0.0203), up=up1, seed=122019)
am2_p = XparMH(X=sam, m=m, V=V, a=a, d=d,
			   x=x, var_d=c(0.0022, 0.0065, 0.0203), up=up2, seed=122019)
am3_p = XparMH(X=sam, m=m, V=V, a=a, d=d,
			   x=x, var_d=c(0.0022, 0.0065, 0.0203), up=up3, seed=122019)

# Taxa de aceitação do algoritmo em cada cenário de tamanho amostral:

am1_p$taxa_acep; am2_p$taxa_acep; am3_p$taxa_acep

# Média; variância; assimetria; curtose e histogramas das amostras geradas:

st_sam_post(am1_p$XparMH_mu)
hist(am1_p$XparMH_mu, breaks=50, prob=T, main="",
	 xlab=expression(paste(mu)), ylab="")
st_sam_post(am2_p$XparMH_mu)
hist(am2_p$XparMH_mu, breaks=50, prob=T, main="",
	 xlab=expression(paste(mu)), ylab="")
st_sam_post(am3_p$XparMH_mu)
hist(am3_p$XparMH_mu, breaks=50, prob=T, main="",
	 xlab=expression(paste(mu)), ylab="")

st_sam_post(am1_p$XparMH_s2)
hist(am1_p$XparMH_s2, breaks=50, prob=T, main="",
	 xlab=expression(paste(sigma^2)), ylab="")
st_sam_post(am2_p$XparMH_s2)
hist(am2_p$XparMH_s2, breaks=50, prob=T, main="",
	 xlab=expression(paste(sigma^2)), ylab="")
st_sam_post(am3_p$XparMH_s2)
hist(am3_p$XparMH_s2, breaks=50, prob=T, main="",
	 xlab=expression(paste(sigma^2)), ylab="")

st_sam_post(am1_p$XparMH_nu)
hist(am1_p$XparMH_nu, breaks=50, prob=T, main="",
	 xlab=expression(paste(nu)), ylab="")
st_sam_post(am2_p$XparMH_nu)
hist(am2_p$XparMH_nu, breaks=50, prob=T, main="",
	 xlab=expression(paste(nu)), ylab="")
st_sam_post(am3_p$XparMH_nu)
hist(am3_p$XparMH_nu, breaks=50, prob=T, main="",
	 xlab=expression(paste(nu)), ylab="")
\end{verbatim}

\newpage

\begin{verbatim}
# Gráficos de convergência e de autocorrelação das cadeias geradas:

library(coda)

par(mar = c(5,5,3,2), mfrow=c(3,1))

traceplot(mcmc(am1_p$XparMH_mu), ylab=expression(paste(mu)))
traceplot(mcmc(am2_p$XparMH_mu), ylab=expression(paste(mu)))
traceplot(mcmc(am3_p$XparMH_mu), ylab=expression(paste(mu)))

plot(acf(am1_p$XparMH_mu, plot=F), main="")
plot(acf(am2_p$XparMH_mu, plot=F), main="")
plot(acf(am3_p$XparMH_mu, plot=F), main="")

traceplot(mcmc(am1_p$XparMH_s2), ylab=expression(paste(sigma^2)))
traceplot(mcmc(am2_p$XparMH_s2), ylab=expression(paste(sigma^2)))
traceplot(mcmc(am3_p$XparMH_s2), ylab=expression(paste(sigma^2)))

plot(acf(am1_p$XparMH_s2, plot=F), main="")
plot(acf(am2_p$XparMH_s2, plot=F), main="")
plot(acf(am3_p$XparMH_s2, plot=F), main="")

traceplot(mcmc(am1_p$XparMH_nu), ylab=expression(paste(nu)))
traceplot(mcmc(am2_p$XparMH_nu), ylab=expression(paste(nu)))
traceplot(mcmc(am3_p$XparMH_nu), ylab=expression(paste(nu)))

plot(acf(am1_p$XparMH_nu, plot=F), main="")
plot(acf(am2_p$XparMH_nu, plot=F), main="")
plot(acf(am3_p$XparMH_nu, plot=F), main="")
\end{verbatim}